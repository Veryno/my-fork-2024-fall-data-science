{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First print your name in the cell below then save this file. (or something nice about your instructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3432549994.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Yaacob Abdullah\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# In this cell print your name \n",
    "\n",
    "Yaacob Abdullah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling with Pandas exercise\n",
    "* For this exercise we will be using the `listings.csv` data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data file using `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data here\n",
    "df = pd.read_csv('data/listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Filtering\n",
    "\n",
    "Return the following subsets of the dataframe.\n",
    "\n",
    "1. How many listings are there with a price less than 100? \n",
    "\n",
    "\n",
    "2. Find how many listings there are in just Brooklyn.\n",
    "\n",
    "\n",
    "3. Find how many listings there are in Brooklyn with a price less than 100.\n",
    "\n",
    "\n",
    "4. Using `.isin()` select anyone that has the host name of Michael, David, John, and Daniel.\n",
    "\n",
    "\n",
    "5. Create a new column called `adjusted_price` that has $100 added to every listing in Williamsburg.  The prices for all other listings should be the same as the were before. \n",
    "\n",
    "\n",
    "6. What % of the rooms are private, and what % of the rooms are shared.  \n",
    "    * Hint, use `.value_counts()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of listings with a price less than 100: 22778\n"
     ]
    }
   ],
   "source": [
    "# 1. How many listings are there with a price less than 100? \n",
    "\n",
    "listings_below_100 = df[df['price'] < 100]\n",
    "count_below_100 = listings_below_100.shape[0]\n",
    "print(f\"Number of listings with a price less than 100: {count_below_100}\")\n",
    "\n",
    "# Number of listings with a price less than 100: 22778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of listings in Brooklyn: 18632\n"
     ]
    }
   ],
   "source": [
    "# 2. Make a new DataFrame of listings in Brooklyn named `df_bk` \n",
    "# and find how many listings in just Brooklyn.\n",
    "brooklyn_listings = df[df['neighbourhood_group'] == 'Brooklyn']\n",
    "count_brooklyn = brooklyn_listings.shape[0]\n",
    "print(f\"Number of listings in Brooklyn: {count_brooklyn}\")\n",
    "\n",
    "# Number of listings in Brooklyn: 18632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of listings in Brooklyn with price less than 100: 10473\n"
     ]
    }
   ],
   "source": [
    "# 3. Find how many listings there are in Brooklyn with a price less than 100.\n",
    "\n",
    "brooklyn_below_100 = df[(df['neighbourhood_group'] == 'Brooklyn') & (df['price'] < 100)]\n",
    "count_brooklyn_below_100 = brooklyn_below_100.shape[0]\n",
    "print(f\"Number of listings in Brooklyn with price less than 100: {count_brooklyn_below_100}\")\n",
    "\n",
    "# Number of listings in Brooklyn with price less than 100: 10473\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                               name    host_id  \\\n",
      "52        16595  LOFT HAVEN ~ Six Windows ~ Bricks ~ Plants ~ Q...      64522   \n",
      "201       61747              Cozy,  Brooklyn, Prospect Park Studio     299370   \n",
      "209       62903  Beautiful modern studio apartment in heart of NYC     306605   \n",
      "220       64015                       Prime East Village 1 Bedroom     146944   \n",
      "260       74073       Food & Music Dream Apartment in Williamsburg     211877   \n",
      "...         ...                                                ...        ...   \n",
      "46362  44639591  Central & Stylish 1 Bedroom Apt - Heart of Che...  286136716   \n",
      "46396  44661297                       Flushing Sunshine home  #101  361579037   \n",
      "46403  44662157                        Flushing Sunshine home #102  361579037   \n",
      "46455  44697211                           Davidâ€™s Queen Sized Room  343477029   \n",
      "46508  44797527    Long-Term: Furnished Apt in Nolita w/ Amenities   19448640   \n",
      "\n",
      "      host_name neighbourhood_group              neighbourhood  latitude  \\\n",
      "52       Daniel            Brooklyn               Williamsburg  40.70933   \n",
      "201       David            Brooklyn  Prospect-Lefferts Gardens  40.65979   \n",
      "209      Daniel           Manhattan                    Chelsea  40.74238   \n",
      "220       David           Manhattan               East Village  40.72807   \n",
      "260      Daniel            Brooklyn               Williamsburg  40.71113   \n",
      "...         ...                 ...                        ...       ...   \n",
      "46362      John           Manhattan                    Chelsea  40.74568   \n",
      "46396    Daniel              Queens                   Flushing  40.74603   \n",
      "46403    Daniel              Queens                   Flushing  40.74441   \n",
      "46455     David              Queens               Far Rockaway  40.59460   \n",
      "46508     David           Manhattan                     Nolita  40.72289   \n",
      "\n",
      "       longitude        room_type  price  minimum_nights  number_of_reviews  \\\n",
      "52     -73.96792  Entire home/apt    271               1                172   \n",
      "201    -73.96180  Entire home/apt     91              14                 97   \n",
      "209    -73.99567  Entire home/apt    205              15                 68   \n",
      "220    -73.98594  Entire home/apt    200               3                  0   \n",
      "260    -73.96054  Entire home/apt    187              30                 90   \n",
      "...          ...              ...    ...             ...                ...   \n",
      "46362  -73.99694  Entire home/apt    110              30                  0   \n",
      "46396  -73.82837     Private room     52               1                  0   \n",
      "46403  -73.82829     Private room     55               1                  3   \n",
      "46455  -73.75875     Private room     95               1                  0   \n",
      "46508  -73.99400  Entire home/apt    140              30                  0   \n",
      "\n",
      "      last_review  reviews_per_month  calculated_host_listings_count  \\\n",
      "52     2020-07-14               1.44                               1   \n",
      "201    2018-01-31               0.83                               1   \n",
      "209    2019-12-14               0.67                               2   \n",
      "220           NaN                NaN                               1   \n",
      "260    2020-07-31               0.81                               1   \n",
      "...           ...                ...                             ...   \n",
      "46362         NaN                NaN                               3   \n",
      "46396         NaN                NaN                               2   \n",
      "46403  2020-08-16               3.00                               2   \n",
      "46455         NaN                NaN                               1   \n",
      "46508         NaN                NaN                               1   \n",
      "\n",
      "       availability_365  \n",
      "52                  365  \n",
      "201                  44  \n",
      "209                  89  \n",
      "220                   0  \n",
      "260                 261  \n",
      "...                 ...  \n",
      "46362               110  \n",
      "46396               360  \n",
      "46403               365  \n",
      "46455               365  \n",
      "46508               282  \n",
      "\n",
      "[1258 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# 4. Using `.isin()` select anyone that has the host name of Michael, David, John, and Daniel.\n",
    "# How many total are there that have those names\n",
    "selected_hosts = df[df['host_name'].isin(['Michael', 'David', 'John', 'Daniel'])]\n",
    "print(selected_hosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            neighbourhood  price  adjusted_price\n",
      "0                 Midtown    175             175\n",
      "1            Clinton Hill     75              75\n",
      "2      Bedford-Stuyvesant     60              60\n",
      "3             Sunset Park    175             175\n",
      "4          Hell's Kitchen     65              65\n",
      "...                   ...    ...             ...\n",
      "46522            Gramercy    145             145\n",
      "46523  Washington Heights     87              87\n",
      "46524       East Flatbush     59              59\n",
      "46525     Upper West Side     80              80\n",
      "46526           Gravesend     66              66\n",
      "\n",
      "[46527 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5. Create a new column called `adjusted_price` that has $100 added to every listing in Williamsburg.  \n",
    "# The prices for all other listings should be the same as the were before. \n",
    "\n",
    "df['adjusted_price'] = df.apply(lambda row: row['price'] + 100 if row['neighbourhood'] == 'Williamsburg' else row['price'], axis=1)\n",
    "print(df[['neighbourhood', 'price', 'adjusted_price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of private rooms: 45.44%\n",
      "Percentage of shared rooms: 2.12%\n"
     ]
    }
   ],
   "source": [
    "# 6. What % of the rooms are private, and what % of the rooms are shared.  \n",
    "\n",
    "\n",
    "room_counts = df['room_type'].value_counts(normalize=True) * 100\n",
    "print(f\"Percentage of private rooms: {room_counts.get('Private room', 0):.2f}%\")\n",
    "print(f\"Percentage of shared rooms: {room_counts.get('Shared room', 0):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Grouping\n",
    "\n",
    "1. Using `groupby`, count how many listings are in each neighbourhood_group.\n",
    "\n",
    "\n",
    "2. Using `groupby`, find the mean price for each of the neighbourhood_groups. \n",
    "\n",
    "\n",
    "3. Using `groupby` and `.agg()`, find the min and max price for each of the neighbourhood_groups. \n",
    "\n",
    "\n",
    "4. Using `groupby`, find the median price for each room type in each neighbourhood_group.\n",
    "\n",
    "\n",
    "5. Using `groupby` and `.agg()`, find the count, min, max, mean, median, and std of the prices for each room type in each neighbourhood_group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group\n",
      "Bronx             1183\n",
      "Brooklyn         18632\n",
      "Manhattan        20580\n",
      "Queens            5791\n",
      "Staten Island      341\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Using `groupby`, count how many listings are in each neighbourhood_group.\n",
    "\n",
    "listings_by_neighbourhood_group = df.groupby('neighbourhood_group').size()\n",
    "print(listings_by_neighbourhood_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group\n",
      "Bronx             92.751479\n",
      "Brooklyn         120.225258\n",
      "Manhattan        191.880466\n",
      "Queens            99.754965\n",
      "Staten Island    110.947214\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2. Using `groupby`, find the mean price for each of the neighbourhood_groups. \n",
    "\n",
    "mean_price_by_neighbourhood_group = df.groupby('neighbourhood_group')['price'].mean()\n",
    "print(mean_price_by_neighbourhood_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "room_type\n",
      "Entire home/apt    199.395950\n",
      "Hotel room         275.015075\n",
      "Private room        91.453084\n",
      "Shared room         87.063830\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 2.5. Using `groupby`, find the mean price for each room_type. \n",
    "mean_price_by_room_type = df.groupby('room_type')['price'].mean()\n",
    "print(mean_price_by_room_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     min    max\n",
      "neighbourhood_group            \n",
      "Bronx                 16   1404\n",
      "Brooklyn               0  10000\n",
      "Manhattan              0  10000\n",
      "Queens                 0  10000\n",
      "Staten Island         19   1200\n"
     ]
    }
   ],
   "source": [
    "# 3. Using `groupby` and `.agg()`, find the min and max price for each of the neighbourhood_groups. \n",
    "\n",
    "min_max_price_by_neighbourhood_group = df.groupby('neighbourhood_group')['price'].agg(['min', 'max'])\n",
    "print(min_max_price_by_neighbourhood_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group  room_type      \n",
      "Bronx                Entire home/apt    103.0\n",
      "                     Private room        55.0\n",
      "                     Shared room         44.0\n",
      "Brooklyn             Entire home/apt    135.0\n",
      "                     Hotel room         129.0\n",
      "                     Private room        60.0\n",
      "                     Shared room         36.0\n",
      "Manhattan            Entire home/apt    165.0\n",
      "                     Hotel room         210.0\n",
      "                     Private room        80.0\n",
      "                     Shared room         60.0\n",
      "Queens               Entire home/apt    115.0\n",
      "                     Hotel room         149.0\n",
      "                     Private room        55.0\n",
      "                     Shared room         40.0\n",
      "Staten Island        Entire home/apt    111.0\n",
      "                     Private room        55.0\n",
      "                     Shared room         38.0\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. Using `groupby`, find the mean price for each room_type in each neighbourhood_group.\n",
    "\n",
    "median_price_by_room_and_neighbourhood_group = df.groupby(['neighbourhood_group', 'room_type'])['price'].median()\n",
    "print(median_price_by_room_and_neighbourhood_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     count  min    max        mean  median  \\\n",
      "neighbourhood_group room_type                                                \n",
      "Bronx               Entire home/apt    415   25   1404  138.004819   103.0   \n",
      "                    Private room       722   16    700   68.419668    55.0   \n",
      "                    Shared room         46   20    800   66.391304    44.0   \n",
      "Brooklyn            Entire home/apt   9112   20  10000  171.587687   135.0   \n",
      "                    Hotel room          30    0    399  147.300000   129.0   \n",
      "                    Private room      9159   10   2500   71.291189    60.0   \n",
      "                    Shared room        331   15   1500   57.870091    36.0   \n",
      "Manhattan           Entire home/apt  12209    0  10000  231.335572   165.0   \n",
      "                    Hotel room         351    0   2211  292.515670   210.0   \n",
      "                    Private room      7601   10  10000  128.277069    80.0   \n",
      "                    Shared room        419   10  10000  111.735084    60.0   \n",
      "Queens              Entire home/apt   2090   10  10000  150.168900   115.0   \n",
      "                    Hotel room          17    0    249  139.058824   149.0   \n",
      "                    Private room      3499   18   9000   69.972564    55.0   \n",
      "                    Shared room        185   14   3000   89.891892    40.0   \n",
      "Staten Island       Entire home/apt    172   39   1200  151.720930   111.0   \n",
      "                    Private room       163   20    800   70.312883    55.0   \n",
      "                    Shared room          6   19     82   46.000000    38.0   \n",
      "\n",
      "                                            std  \n",
      "neighbourhood_group room_type                    \n",
      "Bronx               Entire home/apt  126.032106  \n",
      "                    Private room      57.337866  \n",
      "                    Shared room      114.442703  \n",
      "Brooklyn            Entire home/apt  236.732843  \n",
      "                    Hotel room        91.153206  \n",
      "                    Private room      69.023165  \n",
      "                    Shared room       92.217618  \n",
      "Manhattan           Entire home/apt  410.306439  \n",
      "                    Hotel room       315.924085  \n",
      "                    Private room     448.677306  \n",
      "                    Shared room      502.728868  \n",
      "Queens              Entire home/apt  252.606739  \n",
      "                    Hotel room        50.743806  \n",
      "                    Private room     163.814468  \n",
      "                    Shared room      275.675158  \n",
      "Staten Island       Entire home/apt  147.518392  \n",
      "                    Private room      70.759593  \n",
      "                    Shared room       28.446441  \n"
     ]
    }
   ],
   "source": [
    "# 5. Using `groupby` and `.agg()`, find the count, min, max, mean, median, and std of the prices \n",
    "# for each room type in each neighbourhood_group.\n",
    "\n",
    "price_stats_by_room_and_neighbourhood_group = df.groupby(['neighbourhood_group', 'room_type'])['price'].agg(\n",
    "    ['count', 'min', 'max', 'mean', 'median', 'std']\n",
    ")\n",
    "print(price_stats_by_room_and_neighbourhood_group)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Merge, and Export files.\n",
    "1. Load the `prices.csv` and the `n_listings.csv`\n",
    "    * Having an error..? Inspect the actual csv file if you're having trouble\n",
    "\n",
    "2. Do join that keeps all the records for each table.\n",
    "    * Neighbourhood groups should include ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island',\n",
    "       'LongIsland']\n",
    "\n",
    "       \n",
    "3. Save your joined csv as `joined.csv` into the data folder. \n",
    "\n",
    "\n",
    "4. Load your saved table and see if it looks the same or different that the DataFrame you used to create it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  neighbourhood_group   mean_price\n",
      "0               Bronx    92.751479\n",
      "1            Brooklyn   120.225258\n",
      "2           Manhattan   191.880466\n",
      "3              Queens    99.754965\n",
      "4       Staten Island   110.947214\n",
      "  neighbourhood_group;n_listings\n",
      "0                     Bronx;1183\n",
      "1                 Brooklyn;18632\n",
      "2                Manhattan;20580\n",
      "3                LongIsland;4121\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the `prices.csv` and the `n_listings.csv`\n",
    "\n",
    "\n",
    "prices_df = pd.read_csv('data/prices.csv')\n",
    "listings_df = pd.read_csv('data/n_listings.csv')\n",
    "\n",
    "print(prices_df.head())\n",
    "print(listings_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'neighbourhood_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h2/7_4rtf6s5g39m2vtjqdv54j00000gn/T/ipykernel_61179/3102054668.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;31m# 2. Do join that keeps all the records for each table.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistings_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neighbourhood_group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'neighbourhood_group'"
     ]
    }
   ],
   "source": [
    "# 2. Do join that keeps all the records for each table.\n",
    "\n",
    "merged_df = pd.merge(prices_df, listings_df, on='neighbourhood_group', how='outer')\n",
    "\n",
    "required_neighbourhoods = ['Bronx', 'Brooklyn', 'Manhattan', 'Queens', 'Staten Island', 'LongIsland']\n",
    "filtered_merged_df = merged_df[merged_df['neighbourhood_group'].isin(required_neighbourhoods)]\n",
    "\n",
    "print(filtered_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Save your joined csv as `joined.csv` into the data folder. \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfiltered_merged_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/joined.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Save your joined csv as `joined.csv` into the data folder. \n",
    "\n",
    "filtered_merged_df.to_csv('data/joined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/joined.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 4. Load your newly saved file, see if it looks the same.  If not, try saving with argument `index=False`\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loaded_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/joined.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_merged_df\u001b[38;5;241m.\u001b[39mequals(loaded_df))  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded_df\u001b[38;5;241m.\u001b[39mhead())  \n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/joined.csv'"
     ]
    }
   ],
   "source": [
    "# 4. Load your newly saved file, see if it looks the same.  If not, try saving with argument `index=False`\n",
    "loaded_df = pd.read_csv('data/joined.csv')\n",
    "print(filtered_merged_df.equals(loaded_df))  \n",
    "print(loaded_df.head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit\n",
    "Every question below this cell is extra credit and optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (Easy) Explore this new PandasAI Package and tell me what its all about because I've never used it. \n",
    "* https://www.youtube.com/watch?v=5w6eZaoDVVk&ab_channel=CodingIsFun  \n",
    "* See if you can use it on the listings.csv to find out some cool info. or answer some of the questions above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (Very Easy) Find other cool Panda packages / add ons and show us what they can do well. And how you installed them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (Medium) Use the grammys.csv data for the next section of questions.\n",
    "\n",
    "1. Who was won Album of the Year in 2016?\n",
    "\n",
    "\n",
    "2. Who won Best Rap Album in 2009?\n",
    "\n",
    "\n",
    "3. How many awards was Kendrick Lamar nomiated for, and how many did he win...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Hard) Load the Game Logs for 2022 and add the column names using a dictionary.  \n",
    "* [Link to the data page](https://www.retrosheet.org/gamelogs/)\n",
    "* [Link to the column names](https://procatinator.com/)\n",
    "* haha, gotta find them yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Extra Hard) Download the files for the past 5 years into a new folder and add them all into one data frame using pandas, then save that new file.\n",
    "* Try to not hard code in the file names. We want to do this programmatically because what if we want to add new/more file names in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
