{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you’ll―of course―overcome them with what you learned in class! 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
      "0    2.4       2          1               430           NaN           315.0   \n",
      "1  3.654       1          1               610           3.0           420.0   \n",
      "2    3.3       1          1               720           4.0           420.0   \n",
      "3    3.2       1          1               430           3.0           420.0   \n",
      "4    3.5       1          1               720           2.0           420.0   \n",
      "\n",
      "   coffee                      comfort_food        comfort_food_reasons  \\\n",
      "0       1                              none       we dont have comfort    \n",
      "1       2       chocolate, chips, ice cream        Stress, bored, anger   \n",
      "2       2   frozen yogurt, pizza, fast food             stress, sadness   \n",
      "3       2  Pizza, Mac and cheese, ice cream                     Boredom   \n",
      "4       2      Ice cream, chocolate, chips   Stress, boredom, cravings    \n",
      "\n",
      "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
      "0                         9.0  ...   1.0     1.0          1            1165.0   \n",
      "1                         1.0  ...   1.0     1.0          2             725.0   \n",
      "2                         1.0  ...   1.0     2.0          5            1165.0   \n",
      "3                         2.0  ...   1.0     2.0          5             725.0   \n",
      "4                         1.0  ...   1.0     1.0          4             940.0   \n",
      "\n",
      "   turkey_calories  type_sports veggies_day  vitamins  waffle_calories  \\\n",
      "0              345   car racing           5         1             1315   \n",
      "1              690  Basketball            4         2              900   \n",
      "2              500         none           5         1              900   \n",
      "3              690          NaN           3         1             1315   \n",
      "4              500     Softball           4         2              760   \n",
      "\n",
      "                     weight  \n",
      "0                       187  \n",
      "1                       155  \n",
      "2  I'm not answering this.   \n",
      "3             Not sure, 240  \n",
      "4                       190  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "food_data_set_path = 'data/food_coded.csv'\n",
    "df_food = pd.read_csv(food_data_set_path)\n",
    "print(df_food.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n",
      "None\n",
      "           Gender   breakfast  calories_chicken  calories_day  calories_scone  \\\n",
      "count  125.000000  125.000000        125.000000    106.000000      124.000000   \n",
      "mean     1.392000    1.112000        577.320000      3.028302      505.241935   \n",
      "std      0.490161    0.316636        131.214156      0.639308      230.840506   \n",
      "min      1.000000    1.000000        265.000000      2.000000      315.000000   \n",
      "25%      1.000000    1.000000        430.000000      3.000000      420.000000   \n",
      "50%      1.000000    1.000000        610.000000      3.000000      420.000000   \n",
      "75%      2.000000    1.000000        720.000000      3.000000      420.000000   \n",
      "max      2.000000    2.000000        720.000000      4.000000      980.000000   \n",
      "\n",
      "          coffee  comfort_food_reasons_coded        cook  \\\n",
      "count  125.00000                  106.000000  122.000000   \n",
      "mean     1.75200                    2.698113    2.786885   \n",
      "std      0.43359                    1.972042    1.038351   \n",
      "min      1.00000                    1.000000    1.000000   \n",
      "25%      2.00000                    2.000000    2.000000   \n",
      "50%      2.00000                    2.000000    3.000000   \n",
      "75%      2.00000                    3.000000    3.000000   \n",
      "max      2.00000                    9.000000    5.000000   \n",
      "\n",
      "       comfort_food_reasons_coded.1     cuisine  ...  persian_food  \\\n",
      "count                    125.000000  108.000000  ...    124.000000   \n",
      "mean                       2.688000    1.388889  ...      2.806452   \n",
      "std                        1.910987    0.974759  ...      1.423824   \n",
      "min                        1.000000    1.000000  ...      1.000000   \n",
      "25%                        2.000000    1.000000  ...      2.000000   \n",
      "50%                        2.000000    1.000000  ...      3.000000   \n",
      "75%                        3.000000    1.000000  ...      4.000000   \n",
      "max                        9.000000    6.000000  ...      5.000000   \n",
      "\n",
      "       self_perception_weight        soup      sports   thai_food  \\\n",
      "count              124.000000  124.000000  123.000000  125.000000   \n",
      "mean                 3.120968    1.217742    1.390244    3.336000   \n",
      "std                  1.115980    0.414385    0.489800    1.436528   \n",
      "min                  1.000000    1.000000    1.000000    1.000000   \n",
      "25%                  2.000000    1.000000    1.000000    2.000000   \n",
      "50%                  3.000000    1.000000    1.000000    3.000000   \n",
      "75%                  4.000000    1.000000    2.000000    5.000000   \n",
      "max                  6.000000    2.000000    2.000000    5.000000   \n",
      "\n",
      "       tortilla_calories  turkey_calories  veggies_day    vitamins  \\\n",
      "count         124.000000       125.000000   125.000000  125.000000   \n",
      "mean          947.580645       555.040000     4.008000    1.512000   \n",
      "std           202.090179       152.370379     1.081337    0.501867   \n",
      "min           580.000000       345.000000     1.000000    1.000000   \n",
      "25%           725.000000       500.000000     3.000000    1.000000   \n",
      "50%           940.000000       500.000000     4.000000    2.000000   \n",
      "75%          1165.000000       690.000000     5.000000    2.000000   \n",
      "max          1165.000000       850.000000     5.000000    2.000000   \n",
      "\n",
      "       waffle_calories  \n",
      "count       125.000000  \n",
      "mean       1073.400000  \n",
      "std         248.667092  \n",
      "min         575.000000  \n",
      "25%         900.000000  \n",
      "50%         900.000000  \n",
      "75%        1315.000000  \n",
      "max        1315.000000  \n",
      "\n",
      "[8 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "print(df_food.info())\n",
    "print(df_food.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n",
      "None\n",
      "           Gender   breakfast  calories_chicken  calories_day  calories_scone  \\\n",
      "count  125.000000  125.000000        125.000000    106.000000      124.000000   \n",
      "mean     1.392000    1.112000        577.320000      3.028302      505.241935   \n",
      "std      0.490161    0.316636        131.214156      0.639308      230.840506   \n",
      "min      1.000000    1.000000        265.000000      2.000000      315.000000   \n",
      "25%      1.000000    1.000000        430.000000      3.000000      420.000000   \n",
      "50%      1.000000    1.000000        610.000000      3.000000      420.000000   \n",
      "75%      2.000000    1.000000        720.000000      3.000000      420.000000   \n",
      "max      2.000000    2.000000        720.000000      4.000000      980.000000   \n",
      "\n",
      "          coffee  comfort_food_reasons_coded        cook  \\\n",
      "count  125.00000                  106.000000  122.000000   \n",
      "mean     1.75200                    2.698113    2.786885   \n",
      "std      0.43359                    1.972042    1.038351   \n",
      "min      1.00000                    1.000000    1.000000   \n",
      "25%      2.00000                    2.000000    2.000000   \n",
      "50%      2.00000                    2.000000    3.000000   \n",
      "75%      2.00000                    3.000000    3.000000   \n",
      "max      2.00000                    9.000000    5.000000   \n",
      "\n",
      "       comfort_food_reasons_coded.1     cuisine  ...  persian_food  \\\n",
      "count                    125.000000  108.000000  ...    124.000000   \n",
      "mean                       2.688000    1.388889  ...      2.806452   \n",
      "std                        1.910987    0.974759  ...      1.423824   \n",
      "min                        1.000000    1.000000  ...      1.000000   \n",
      "25%                        2.000000    1.000000  ...      2.000000   \n",
      "50%                        2.000000    1.000000  ...      3.000000   \n",
      "75%                        3.000000    1.000000  ...      4.000000   \n",
      "max                        9.000000    6.000000  ...      5.000000   \n",
      "\n",
      "       self_perception_weight        soup      sports   thai_food  \\\n",
      "count              124.000000  124.000000  123.000000  125.000000   \n",
      "mean                 3.120968    1.217742    1.390244    3.336000   \n",
      "std                  1.115980    0.414385    0.489800    1.436528   \n",
      "min                  1.000000    1.000000    1.000000    1.000000   \n",
      "25%                  2.000000    1.000000    1.000000    2.000000   \n",
      "50%                  3.000000    1.000000    1.000000    3.000000   \n",
      "75%                  4.000000    1.000000    2.000000    5.000000   \n",
      "max                  6.000000    2.000000    2.000000    5.000000   \n",
      "\n",
      "       tortilla_calories  turkey_calories  veggies_day    vitamins  \\\n",
      "count         124.000000       125.000000   125.000000  125.000000   \n",
      "mean          947.580645       555.040000     4.008000    1.512000   \n",
      "std           202.090179       152.370379     1.081337    0.501867   \n",
      "min           580.000000       345.000000     1.000000    1.000000   \n",
      "25%           725.000000       500.000000     3.000000    1.000000   \n",
      "50%           940.000000       500.000000     4.000000    2.000000   \n",
      "75%          1165.000000       690.000000     5.000000    2.000000   \n",
      "max          1165.000000       850.000000     5.000000    2.000000   \n",
      "\n",
      "       waffle_calories  \n",
      "count       125.000000  \n",
      "mean       1073.400000  \n",
      "std         248.667092  \n",
      "min         575.000000  \n",
      "25%         900.000000  \n",
      "50%         900.000000  \n",
      "75%        1315.000000  \n",
      "max        1315.000000  \n",
      "\n",
      "[8 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "print(df_food.info())\n",
    "print(df_food.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we’d like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. …and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['gender'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remove ‘em.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_food_relevant \u001b[38;5;241m=\u001b[39m \u001b[43mdf_food\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcalories_day\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['gender'] not in index\""
     ]
    }
   ],
   "source": [
    "# Remove ‘em.\n",
    "df_food_relevant = df_food[['calories_day', 'weight', 'gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count ‘em.\n",
    "missing_values = df_food_relevant.isnull().sum()\n",
    "print(\"Missing values in relevant columns:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s―the entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ‘em.\n",
    "df_food_cleaned = df_food_relevant.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix that.\n",
    "\n",
    "df_food_relevant = df_food[['calories_day', 'weight', 'gender']]\n",
    "\n",
    "df_food_relevant['calories_day'] = pd.to_numeric(df_food_relevant['calories_day'], errors='coerce')\n",
    "\n",
    "df_food_cleaned = df_food_relevant.dropna(subset=['calories_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! 😁\n",
    "\n",
    "Let’s save it somewhere to be shipped off to another teammate. 💾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "df_food_cleaned.to_csv('cleaned_food_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "df_salary = pd.read_csv('data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv', delimiter='\\t')\n",
    "print(df_salary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? 🙃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by hand. I’m dead serious.\n",
    "\n",
    "df_salary = pd.read_csv('data/Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv.tsv', delimiter='\\t')\n",
    "df_salary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_salary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Show the column names and their types.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf_salary\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      3\u001b[0m df_salary\u001b[38;5;241m.\u001b[39mdtypes\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_salary' is not defined"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "df_salary.columns\n",
    "df_salary.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh… Ugh! Give these columns easier names to work with first. 🙄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename ‘em.\n",
    "# Non-binding suggestions: timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed\tgender, race\n",
    "df_salary.rename(columns={\n",
    "    'Timestamp': 'timestamp',\n",
    "    'Age': 'age',\n",
    "    'Industry': 'industry',\n",
    "    'Job title': 'title',\n",
    "    'Additional context on job title': 'title_context',\n",
    "    'Annual salary': 'salary',\n",
    "    'Other monetary comp': 'additional_compensation',\n",
    "    'Currency': 'currency',\n",
    "    'Other currency': 'other_currency',\n",
    "    'Additional context on income': 'salary_context',\n",
    "    'Country': 'country',\n",
    "    'State': 'state',\n",
    "    'City': 'city',\n",
    "    'Total years of experience': 'total_yoe',\n",
    "    'Years of experience in field': 'field_yoe',\n",
    "    'Highest level of education completed': 'highest_education_completed',\n",
    "    'Gender': 'gender',\n",
    "    'Race': 'race'\n",
    "}, inplace=True)\n",
    "\n",
    "df_salary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s a lot, and that should not have been easy. 😏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "\n",
    "df_salary['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you’re looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "\n",
    "df_salary_tech = df_salary[df_salary['industry'] == 'Computing/Tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check \n",
    "\n",
    "df_salary_tech['industry'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars 💵 is a euro 💶 or a pound 💷? That sounds like a problem for another day. 🫠\n",
    "\n",
    "For now, let’s just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "\n",
    "df_salary_tech_usd = df_salary_tech[df_salary_tech['currency'] == 'USD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "\n",
    "df_salary_tech_usd['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can’t get our answers with what we currently have, so you’ll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value―say, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace them all with 'US'.\n",
    "\n",
    "top_countries = ['United States', 'USA', 'US', 'U.S.', 'United States of America']\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].replace(top_countries, 'US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count again.\n",
    "\n",
    "df_salary_tech_usd['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BONUS CREDIT: if you’ve resolved it, let’s see how well you did by counting the number of instances of each unique value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s looking good so far. Let’s find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "\n",
    "df_salary_tech_usd.groupby('state')['salary'].agg(['min', 'mean', 'max']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn’t numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix it.\n",
    "\n",
    "df_salary_tech_usd['salary'] = pd.to_numeric(df_salary_tech_usd['salary'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it again. Yeah!\n",
    "\n",
    "df_salary_tech_usd.groupby('state')['salary'].agg(['min', 'mean', 'max']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let’s narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "\n",
    "df_salary_tech_usd['timestamp'] = pd.to_datetime(df_salary_tech_usd['timestamp'], errors='coerce')\n",
    "df_salary_tech_recent = df_salary_tech_usd[df_salary_tech_usd['timestamp'].dt.year.isin([2021, 2022, 2023])]\n",
    "df_salary_tech_recent.groupby('state')['salary'].agg(['min', 'mean', 'max']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you’ve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let’s back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum―say 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you―like say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* 😜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
